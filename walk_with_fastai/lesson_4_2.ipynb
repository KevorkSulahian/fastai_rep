{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.PETS)/'images'\n",
    "fnames = get_image_files(path)\n",
    "pat = r'/([^/]+)_\\d+.*'\n",
    "batch_tfms = [*aug_transforms(size=224, max_warp=0), Normalize.from_stats(*imagenet_stats)]\n",
    "item_tfms = RandomResizedCrop(460, min_scale=0.75, ratio=(1.,1.))\n",
    "bs=64\n",
    "\n",
    "pets = DataBlock(\n",
    "    blocks=(ImageBlock, CategoryBlock),\n",
    "     get_items=get_image_files,\n",
    "     splitter=RandomSplitter(),\n",
    "     get_y=RegexLabeller(pat = r'/([^/]+)_\\d+.*'),\n",
    "     item_tfms=item_tfms,\n",
    "     batch_tfms=batch_tfms\n",
    ")\n",
    "dls = pets.dataloaders(path, bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting timm\n",
      "  Downloading timm-0.9.12-py3-none-any.whl.metadata (60 kB)\n",
      "     ---------------------------------------- 0.0/60.6 kB ? eta -:--:--\n",
      "     ------ --------------------------------- 10.2/60.6 kB ? eta -:--:--\n",
      "     ------------ ------------------------- 20.5/60.6 kB 217.9 kB/s eta 0:00:01\n",
      "     ------------------- ------------------ 30.7/60.6 kB 186.2 kB/s eta 0:00:01\n",
      "     -------------------------------- ----- 51.2/60.6 kB 260.9 kB/s eta 0:00:01\n",
      "     -------------------------------------- 60.6/60.6 kB 268.0 kB/s eta 0:00:00\n",
      "Requirement already satisfied: torch>=1.7 in c:\\users\\kevol\\anaconda3\\envs\\fastai\\lib\\site-packages (from timm) (2.1.2+cu118)\n",
      "Requirement already satisfied: torchvision in c:\\users\\kevol\\anaconda3\\envs\\fastai\\lib\\site-packages (from timm) (0.16.2+cu118)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\kevol\\anaconda3\\envs\\fastai\\lib\\site-packages (from timm) (6.0.1)\n",
      "Collecting huggingface-hub (from timm)\n",
      "  Downloading huggingface_hub-0.20.3-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting safetensors (from timm)\n",
      "  Downloading safetensors-0.4.2-cp311-none-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\kevol\\anaconda3\\envs\\fastai\\lib\\site-packages (from torch>=1.7->timm) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\kevol\\anaconda3\\envs\\fastai\\lib\\site-packages (from torch>=1.7->timm) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\kevol\\anaconda3\\envs\\fastai\\lib\\site-packages (from torch>=1.7->timm) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\kevol\\anaconda3\\envs\\fastai\\lib\\site-packages (from torch>=1.7->timm) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\kevol\\anaconda3\\envs\\fastai\\lib\\site-packages (from torch>=1.7->timm) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\kevol\\anaconda3\\envs\\fastai\\lib\\site-packages (from torch>=1.7->timm) (2023.12.2)\n",
      "Requirement already satisfied: requests in c:\\users\\kevol\\anaconda3\\envs\\fastai\\lib\\site-packages (from huggingface-hub->timm) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\kevol\\anaconda3\\envs\\fastai\\lib\\site-packages (from huggingface-hub->timm) (4.66.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\kevol\\anaconda3\\envs\\fastai\\lib\\site-packages (from huggingface-hub->timm) (23.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\kevol\\anaconda3\\envs\\fastai\\lib\\site-packages (from torchvision->timm) (1.26.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\kevol\\anaconda3\\envs\\fastai\\lib\\site-packages (from torchvision->timm) (10.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\kevol\\anaconda3\\envs\\fastai\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub->timm) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\kevol\\anaconda3\\envs\\fastai\\lib\\site-packages (from jinja2->torch>=1.7->timm) (2.1.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kevol\\anaconda3\\envs\\fastai\\lib\\site-packages (from requests->huggingface-hub->timm) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kevol\\anaconda3\\envs\\fastai\\lib\\site-packages (from requests->huggingface-hub->timm) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kevol\\anaconda3\\envs\\fastai\\lib\\site-packages (from requests->huggingface-hub->timm) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kevol\\anaconda3\\envs\\fastai\\lib\\site-packages (from requests->huggingface-hub->timm) (2023.11.17)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\kevol\\anaconda3\\envs\\fastai\\lib\\site-packages (from sympy->torch>=1.7->timm) (1.3.0)\n",
      "Downloading timm-0.9.12-py3-none-any.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.0/2.2 MB 2.0 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 0.1/2.2 MB 1.3 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 0.2/2.2 MB 1.5 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 0.4/2.2 MB 2.4 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 0.6/2.2 MB 2.9 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 1.0/2.2 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.6/2.2 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.2/2.2 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 5.9 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.20.3-py3-none-any.whl (330 kB)\n",
      "   ---------------------------------------- 0.0/330.1 kB ? eta -:--:--\n",
      "   --------------------------------------- 330.1/330.1 kB 20.0 MB/s eta 0:00:00\n",
      "Downloading safetensors-0.4.2-cp311-none-win_amd64.whl (269 kB)\n",
      "   ---------------------------------------- 0.0/269.6 kB ? eta -:--:--\n",
      "   --------------------------------------- 269.6/269.6 kB 17.3 MB/s eta 0:00:00\n",
      "Installing collected packages: safetensors, huggingface-hub, timm\n",
      "Successfully installed huggingface-hub-0.20.3 safetensors-0.4.2 timm-0.9.12\n"
     ]
    }
   ],
   "source": [
    "!pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kevol\\anaconda3\\envs\\fastai\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "model.safetensors: 100%|██████████| 22.9M/22.9M [00:01<00:00, 17.8MB/s]\n",
      "c:\\Users\\kevol\\anaconda3\\envs\\fastai\\Lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\kevol\\.cache\\huggingface\\hub\\models--timm--vit_tiny_patch16_224.augreg_in21k_ft_in1k. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "from timm import create_model\n",
    "net = create_model(\"vit_tiny_patch16_224\", pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to C:\\Users\\kevol/.cache\\torch\\hub\\checkpoints\\resnet18-f37072fd.pth\n",
      "100%|██████████| 44.7M/44.7M [00:01<00:00, 25.7MB/s]\n"
     ]
    }
   ],
   "source": [
    "learn = vision_learner(dls, models.resnet18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): AdaptiveConcatPool2d(\n",
       "    (ap): AdaptiveAvgPool2d(output_size=1)\n",
       "    (mp): AdaptiveMaxPool2d(output_size=1)\n",
       "  )\n",
       "  (1): fastai.layers.Flatten(full=False)\n",
       "  (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (3): Dropout(p=0.25, inplace=False)\n",
       "  (4): Linear(in_features=1024, out_features=512, bias=False)\n",
       "  (5): ReLU(inplace=True)\n",
       "  (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (7): Dropout(p=0.5, inplace=False)\n",
       "  (8): Linear(in_features=512, out_features=37, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.model[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'VisionTransformer' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mnet\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'VisionTransformer' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "net[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        self.l1 = nn.Linear(1,1)\n",
    "        self.l2 = nn.linear(1,1)\n",
    "    def forward(self, x):\n",
    "        return self.l2(self.l1(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Sequential):\n",
    "    def __init__(self):\n",
    "        layers = [\n",
    "            nn.Linear(1,1),\n",
    "            nn.Linear(1,1),\n",
    "        ]\n",
    "        super().__init__(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Linear(in_features=1, out_features=1, bias=True),\n",
       " Linear(in_features=1, out_features=1, bias=True))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = MyModel()\n",
    "net[0], net[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_cut_model(model:nn.Module, cut:typing.Union[int, typing.Callable]):\n",
    "    \"\"\"\n",
    "    Cuts `model` into an `nn.Sequential` based on `cut`. \n",
    "    \"\"\"\n",
    "    if isinstance(cut, int):\n",
    "        return nn.Sequential(*list(model.children())[:cut])\n",
    "    elif callable(cut):\n",
    "        return cut(model)\n",
    "    else:\n",
    "        raise NameError(\"`cut` must either be an integer or a function\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTimmBody(nn.Module):\n",
    "    \"\"\"\n",
    "    A small submodule to work with `timm` models more easily\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        model, \n",
    "        pretrained:bool=True, \n",
    "        cut=None, \n",
    "        n_in:int=3\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.needs_pooling = model.default_cfg.get('pool_size', None)\n",
    "        if cut is None:\n",
    "            self.model = model\n",
    "        else:\n",
    "            self.model = custom_cut_model(model, cut)\n",
    "    \n",
    "    def forward(self, x): \n",
    "        if self.needs_pooling:\n",
    "            return self.model.forward_features(x)\n",
    "        else:\n",
    "            return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "body = CustomTimmBody(\n",
    "    create_model(\"vit_tiny_patch16_224\", pretrained=True, num_classes=0, in_chans=3)\n",
    ").train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "head = create_head(body.model.num_features, dls.c, pool=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (1): Dropout(p=0.25, inplace=False)\n",
       "  (2): Linear(in_features=192, out_features=512, bias=False)\n",
       "  (3): ReLU(inplace=True)\n",
       "  (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (5): Dropout(p=0.5, inplace=False)\n",
       "  (6): Linear(in_features=512, out_features=37, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(2,3,224,224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.2664, -1.4011,  0.9820,  0.2703, -0.1990, -0.6010, -0.3267,  1.3051,\n",
       "          -0.4930, -1.2725, -0.3302,  0.4171,  0.4434, -0.0224, -0.3191, -0.9780,\n",
       "          -0.3840, -0.3713, -0.2089,  1.1003,  0.3625, -0.2849,  0.2323,  0.8902,\n",
       "           0.8680, -1.2252, -0.8373, -0.7704,  1.5352,  0.6110, -0.6006, -0.0841,\n",
       "           0.9687, -0.8723, -0.3574, -1.4446, -0.5222],\n",
       "         [ 0.8661,  1.3563, -0.1964,  0.2642, -0.0186,  0.3100, -0.5519,  0.1121,\n",
       "           0.5343,  1.9768, -1.6937, -0.4661,  0.2464,  0.1269, -0.0559,  0.6972,\n",
       "           0.2942,  1.0785,  0.5170, -0.8845, -0.1946,  0.3110,  0.5366, -0.6239,\n",
       "           0.5172,  1.3059,  0.6528,  0.9186, -1.0411, -0.1129,  0.0933,  0.7153,\n",
       "          -0.3450,  0.6841, -0.6316,  0.8465,  1.3900]], grad_fn=<MmBackward0>),\n",
       " torch.Size([2, 37]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = head(body(x))\n",
    "out, out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_init(head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_split_func(model:nn.Module):\n",
    "    \"A function that splits layers by their parameters\"\n",
    "    return L(model[0], model[1:]).map(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitter(model):\n",
    "    \"Splits a model by head and body\"\n",
    "    return L(model[0], model[1]).map(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(\n",
    "    dls,\n",
    "    nn.Sequential(body, head),\n",
    "    splitter=splitter\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l trainable params: 5,605,056\n",
      "Total non-trainable params: 0\n",
      "\n",
      "Optimizer used: <function Adam at 0x000002095644B920>\n",
      "Loss function: FlattenedLoss of CrossEntropyLoss()\n",
      "\n",
      "Callbacks:\n",
      "  - TrainEvalCallback\n",
      "  - CastToTensor\n",
      "  - Recorder\n",
      "  - ProgressCallback\n"
     ]
    }
   ],
   "source": [
    "print(learn.summary()[-250:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l trainable params: 128,256\n",
      "Total non-trainable params: 5,476,800\n",
      "\n",
      "Optimizer used: <function Adam at 0x000002095644B920>\n",
      "Loss function: FlattenedLoss of CrossEntropyLoss()\n",
      "\n",
      "Model frozen up to parameter group #1\n",
      "\n",
      "Callbacks:\n",
      "  - TrainEvalCallback\n",
      "  - CastToTensor\n",
      "  - Recorder\n",
      "  - ProgressCallback\n"
     ]
    }
   ],
   "source": [
    "print(learn.summary()[-295:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
